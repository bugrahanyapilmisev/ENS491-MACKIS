# build_graph.py
import sys
import os
import pandas as pd
from tqdm import tqdm

# Path ayarlarÄ± (backend modÃ¼llerini bulmasÄ± iÃ§in)
sys.path.append(os.path.join(os.getcwd(), "backend"))

from database import SessionLocal
from services.graph_service import GraphService
from dotenv import load_dotenv

load_dotenv("backend/.env")

CHUNK_PATH = os.path.join(os.getenv("PREPROCESSING_PATH"), "checkpoints_plus2", "chunks_plus2.parquet")

def main():
    print("ğŸš€ Knowledge Graph Ä°nÅŸasÄ± BaÅŸlÄ±yor...")
    
    if not os.path.exists(CHUNK_PATH):
        print(f"âŒ Parquet dosyasÄ± bulunamadÄ±: {CHUNK_PATH}")
        return

    # Veriyi Oku
    df = pd.read_parquet(CHUNK_PATH)
    print(f"ğŸ“„ Toplam {len(df)} chunk var. Ä°ÅŸlem baÅŸlÄ±yor...")

    db = SessionLocal()
    graph_service = GraphService(db)

    # Ã–rnek olarak ilk 50 chunk'Ä± iÅŸleyelim (Hepsini yapmak saatler sÃ¼rer, Ã¶nce test et)
    sample_df = df.head(50) 

    for index, row in tqdm(sample_df.iterrows(), total=len(sample_df)):
        text = row['content']
        # Metadata'dan varsa doc_id alabiliriz, ÅŸimdilik None geÃ§iyoruz
        
        # 1. LLM ile Ã‡Ä±karÄ±m Yap
        triples = graph_service.extract_triples_from_text(text)
        
        # 2. VeritabanÄ±na Kaydet
        if triples:
            graph_service.save_triples_to_db(triples)

    print("âœ… Graph Ä°nÅŸasÄ± TamamlandÄ±!")
    db.close()

if __name__ == "__main__":
    main()